# Using CDFt packages
library("CDFt")

# Using two samples test packages
library("twosamples")

# Using packages for reading arguments
library("optparse")
 
# Bootstrap
nboots <- as.integer(1)
usedalpha <- 0.05

# Option list
option_list = list(
    make_option(c("-o", "--observation"), type="character", default=NULL, help="Observation (reference) data file", metavar="character"),
    make_option(c("-m", "--modeloutput"), type="character", default=NULL, help="Simulation from WRF model (normally historical period)", metavar="character"),
    make_option(c("-v", "--validation"), type="character", default=NULL, help="Few statistical validations, e.g., CramerVonMises, KolmogorovSmirnov", metavar="character")
); 
 
# Function for applying CDFt
f_cdft <- function (O, Gp, Gf) {
  # Use the CDFt method
  CT <- CDFt(O,Gp,Gf)
  ds <- CT$DS
  # 
  return(ds)
}

# Function for "Singularity Stochastic Removal" (SSR)
ssr <- function (t, th) {
  # Over careful guy !
  t_new <- t
  # A random variable distributed uniformly between 0 and th
  # "runif() will not generate either of the extreme values 
  # unless max = min or max-min is small compared to min !
  z <- runif(length(t_new), min=0, max=th)
  # Replacing
  id <- t_new == 0 & !is.na(t_new)
  t_new[id] <- z[id]
  #
  return(t_new)
}

# Function for CvM and K-S test (counting "passed" cases)
two_sample_test <- function(a,b,alpha) {
  # Use "twosamples" package
  cvm_t <- cvm_test(a,b)
  ks_t <- ks_test(a,b)
  # Get p-value
  cvm <- if (cvm_t[2] > alpha) 1 else 0
  ks <- if (ks_t[2] > alpha) 1 else 0
  # Get it !
  return(c(cvm,ks))
}

# Function for CvM and K-S test (return statistics values)
test_stat_value <- function(a,b,alpha) {
  # Use "twosamples" package
  cvm_t <- cvm_test(a,b)
  ks_t <- ks_test(a,b)
  dts_t <- dts_test(a,b)
  # Get it !
  return(c(as.numeric(cvm_t[1]),as.numeric(ks_t[1]),as.numeric(dts_t[1])))
}

# Read arguments 
opt_parser = OptionParser(option_list=option_list);
opt = parse_args(opt_parser);

if (is.null(opt$observation)){
  print_help(opt_parser)
  stop("At least one argument must be supplied (input file).n", call.=FALSE)
}

# Read station data
obs <- read.csv(file = opt$observation)

# Read model output
mod <- read.csv(file = opt$modeloutput)

# Saving some statistics test
statout <- data.frame(matrix(ncol=6, nrow=0))
# Compare bootstrap p-value with the rejection threshold and, save only:
#  1 : it passed the test (p-value > alpha) : samples may be from same distribution
#  0 : null rejected 
#tmp <- c('CVM_passcode','KS_passcode')
# With bootstrap (e.g., 1000 times), it's about how many time it passed
#tmp <- c('CVM_percent','KS_percent')
# I need Before and After
tmp <- c('CVM_before','KS_before','DTS_before','CVM_after','KS_after','DTS_after')
colnames(statout) <- tmp

# First columns is "Time"
for ( i in colnames(obs)[2:length(colnames(obs))]) {

  # Get one series each time
  O <- as.numeric(obs[,i])
  Gp <- as.numeric(mod[,i])

  # 2/3 rule: 2/3 first for calibration and 1/3 last for validation
  n <- length(Gp)
  l <- as.integer(2/3*n)

  # Bootstrap for bias-correction steps
  # Keep it here but no meaning now (!)
  # Maybe adding this step later
  for ( j in seq_len(nboots)){

    # 100 % of data (not 75 % as nboots = 1)
    fraction = 1.0

    Gp_cal <- sample(Gp[1:l], as.integer(fraction*l))
    Gp_val <- sample(Gp[(l+1):n], as.integer(fraction*(n-l)))

    O_cal <- sample(O[1:l], as.integer(fraction*l))
    O_val <- sample(O[(l+1):n], as.integer(fraction*(n-l)))

    # Determine a positive precipitation threshold th
    th <- min(O_cal[O_cal>0], Gp_cal[Gp_cal>0], Gp_val[Gp_val>0], na.rm=TRUE)
  
    # Singularity Stochastic Removal
    O_ssr <- ssr(O_cal,th)
    Gp_ssr <- ssr(Gp_cal,th)
    Gf_ssr <- ssr(Gp_val,th)
  
    # Now use CDFt function
    bc <- f_cdft(O_ssr, Gp_ssr, Gf_ssr)
  
    # Bias-corrected data lower than th are set to 0
    bc[bc < th] <- 0
  
    # Now, do K-S and CvM tests
    # Should I remove values in "bc" corresponding to NA in "O_val"?
    # In term of distribution, (maybe) NO
    after <- test_stat_value(bc,na.omit(O_val),usedalpha)

    # And before bias correction 
    before <- test_stat_value(Gp_val,na.omit(O_val),usedalpha)

    # Get the outputs
    statout[nrow(statout) + 1, ] <- c(before,after)

  }
}

# Write output
write.csv(statout,file = opt$validation, row.names=FALSE)
