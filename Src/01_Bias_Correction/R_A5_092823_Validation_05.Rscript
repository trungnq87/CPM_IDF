# Using CDFt packages
library("CDFt")

# Using two samples test packages
library("twosamples")

# Using packages for reading arguments
library("optparse")
 
# Significant test threshold
usedalpha <- 0.05

# Option list
option_list = list(
    make_option(c("-o", "--observation"), type="character", default=NULL, help="Observation (reference) data file", metavar="character"),
    make_option(c("-m", "--modeloutput"), type="character", default=NULL, help="Simulation from WRF model (normally historical period)", metavar="character"),
    make_option(c("-b", "--biascorrected"), type="character", default=NULL, help="Bias-corrected WRF", metavar="character"),
    make_option(c("-v", "--validation"), type="character", default=NULL, help="Few statistical validations, e.g., CramerVonMises, KolmogorovSmirnov", metavar="character")
); 
 
# Function for applying CDFt
f_cdft <- function (O, Gp, Gf) {
  # Use the CDFt method
  CT <- CDFt(O,Gp,Gf)
  ds <- CT$DS
  # 
  return(ds)
}

# Function for "Singularity Stochastic Removal" (SSR)
ssr <- function (t, th) {
  # Over careful guy !
  t_new <- t
  # A random variable distributed uniformly between 0 and th
  # "runif() will not generate either of the extreme values 
  # unless max = min or max-min is small compared to min !
  z <- runif(length(t_new), min=0, max=th)
  # Replacing
  id <- t_new == 0 & !is.na(t_new)
  t_new[id] <- z[id]
  #
  return(t_new)
}

# Function for CvM and K-S test
two_sample_test <- function(a,b,alpha) {
  # Use "twosamples" package
  cvm_t <- cvm_test(a,b)
  ks_t <- ks_test(a,b)
  # Get p-value
  cvm <- if (cvm_t[2] > alpha) 1 else 0
  ks <- if (ks_t[2] > alpha) 1 else 0
  # Get it !
  return(c(cvm,ks))
}

# Function for DTS test
dts_test_stat <- function(a,b,alpha) {
  # Use "twosamples" package
  dts_t <- dts_test(a,b)
  # Get p-value
  dts <- if (dts_t[2] > alpha) 1 else 0
  # Get it !
  return(dts)
}

# Read arguments 
opt_parser = OptionParser(option_list=option_list);
opt = parse_args(opt_parser);

if (is.null(opt$observation)){
  print_help(opt_parser)
  stop("At least one argument must be supplied (input file).n", call.=FALSE)
}

# Read station data
obs <- read.csv(file = opt$observation)

# Read model output
mod <- read.csv(file = opt$modeloutput)

# Read bias-corrected data
bc <- read.csv(file = opt$biascorrected)

# Saving some statistics test
statout <- data.frame(matrix(ncol=2, nrow=0))
# Compare bootstrap p-value with the rejection threshold and, save only:
#  1 : it passed the test (p-value > alpha) : samples may be from same distribution
#  0 : null rejected 
#tmp <- c('CVM_passcode','KS_passcode')
# With bootstrap (e.g., 1000 times), it's about how many time it passed
#tmp <- c('CVM_percent','KS_percent')
# I need Before and After
#tmp <- c('CVM_before','CVM_after','KS_before','KS_after')
tmp <- c('DTS_before','DTS_after')
colnames(statout) <- tmp

# First columns is "Time"
for ( i in colnames(obs)[2:length(colnames(obs))]) {

  # Get one series each time
  O <- as.numeric(obs[,i])
  Gp <- as.numeric(mod[,i])
  Gf <- as.numeric(bc[,i])

  # Now, do K-S and CvM tests
  after <- dts_test_stat(na.omit(Gf),na.omit(O),usedalpha)

  # And before bias correction 
  before <- dts_test_stat(na.omit(Gp),na.omit(O),usedalpha)

  statout[nrow(statout) + 1, ] <- c(before,after)
}

# Write output
write.csv(statout,file = opt$validation, row.names=FALSE)
